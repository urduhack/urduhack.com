{
  
    
        "post0": {
            "title": "Urdu unicode ranges explained",
            "content": "Urdu language has 46 Alphabets, 10 Digits, 6 Punctuations and 6 Diacritics characters. . The Urdu alphabet is the right-to-left alphabet used for the Urdu language. It is a modification of the Persian alphabet known as Perso-Arabic, which is itself a derivative of the Arabic alphabet. The Urdu alphabet has up to 58 letters with 39 basic letters and no distinct letter cases, the Urdu alphabet is typically written in the calligraphic Nastaʿlīq script. . What is Encoding . Character encoding may be defined as assigning a unique number to each language character to be processed by the computer. Whenever a character is input from keyboard or other input devices, this particular code is generated internally in the computer. Arbitrary encoding may be defined for any application (e.g. 80 for letter ‘a’, 81 for letter ‘b’). However, if different vendors are defining arbitrary encodings, their encodings may not agree with one another. With the advent of the Internet, it has now become increasingly essential to standardize the encoding scheme because users are accessing data created by a variety of sources through web browsers (a single application). Realizing the significance of standardizing encoding, work was done early for English and American Standard Code for Information Interchange (ASCII) was defined in 1968. This standard had 128 slots defined using 7 bits by American National Standards Institute (ANSI). . What is Unicode . Initially most documentation was done in a single language, therefore 8-bit single language code pages served the need. However, in 1990s, with increasing needs for multi-lingual documents (where one could require Japanese and Arabic in the same document), it was realized that defining 8-bit code pages were not a scalable solution. Adding code pages for various languages and scripts and using them together in one application created a lot of difficulty and complexity in processing because users had to keep toggling between them. . To address this issue, major vendors got together and created Unicode consortium (www.unicode.org). This consortium started working on developing a singular, unified and universal code chart which would contain all characters of all languages. As 8-bit (256 slots) code pages were insufficient for this requirement, Unicode character encoding standard was developed using 16 bits (65536 slots). This space has been divided to cater to various scripts and thus bypassed the need for toggling for different languages. . Urdu Unicode Range(0600-06ff) . Arabic is a superset of Urdu, Persian, and Sindhi. Urdu, Arabic, Persian, Sindhi, all occupy the same range i.e. 0600-06FF. But different code points for some different characters. . . !pip install &#39;urduhack[tf]&#39; . Collecting urduhack[tf] Downloading urduhack-1.1.1-py3-none-any.whl (105 kB) |████████████████████████████████| 105 kB 179 kB/s eta 0:00:01 Requirement already satisfied: tf2crf in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from urduhack[tf]) (0.1.17) Requirement already satisfied: Click~=7.1 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from urduhack[tf]) (7.1.2) Requirement already satisfied: tensorflow-datasets~=3.1 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from urduhack[tf]) (3.2.1) Requirement already satisfied: regex in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from urduhack[tf]) (2020.7.14) Requirement already satisfied: tensorflow~=2.2; extra == &#34;tf&#34; in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from urduhack[tf]) (2.3.0) Requirement already satisfied: tensorflow-addons&gt;=0.8.2 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tf2crf-&gt;urduhack[tf]) (0.11.2) Requirement already satisfied: requests&gt;=2.19.0 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow-datasets~=3.1-&gt;urduhack[tf]) (2.24.0) Requirement already satisfied: tqdm in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow-datasets~=3.1-&gt;urduhack[tf]) (4.48.2) Requirement already satisfied: attrs&gt;=18.1.0 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow-datasets~=3.1-&gt;urduhack[tf]) (19.3.0) Requirement already satisfied: six in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow-datasets~=3.1-&gt;urduhack[tf]) (1.15.0) Requirement already satisfied: tensorflow-metadata in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow-datasets~=3.1-&gt;urduhack[tf]) (0.23.0) Requirement already satisfied: termcolor in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow-datasets~=3.1-&gt;urduhack[tf]) (1.1.0) Requirement already satisfied: dill in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow-datasets~=3.1-&gt;urduhack[tf]) (0.3.2) Requirement already satisfied: protobuf&gt;=3.6.1 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow-datasets~=3.1-&gt;urduhack[tf]) (3.13.0) Requirement already satisfied: wrapt in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow-datasets~=3.1-&gt;urduhack[tf]) (1.12.1) Requirement already satisfied: numpy in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow-datasets~=3.1-&gt;urduhack[tf]) (1.18.5) Requirement already satisfied: absl-py in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow-datasets~=3.1-&gt;urduhack[tf]) (0.10.0) Requirement already satisfied: future in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow-datasets~=3.1-&gt;urduhack[tf]) (0.18.2) Requirement already satisfied: promise in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow-datasets~=3.1-&gt;urduhack[tf]) (2.3) Requirement already satisfied: wheel&gt;=0.26 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (0.35.1) Requirement already satisfied: scipy==1.4.1 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (1.4.1) Requirement already satisfied: h5py&lt;2.11.0,&gt;=2.10.0 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (2.10.0) Requirement already satisfied: gast==0.3.3 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (0.3.3) Requirement already satisfied: tensorflow-estimator&lt;2.4.0,&gt;=2.3.0 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (2.3.0) Requirement already satisfied: tensorboard&lt;3,&gt;=2.3.0 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (2.3.0) Requirement already satisfied: keras-preprocessing&lt;1.2,&gt;=1.1.1 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (1.1.2) Requirement already satisfied: astunparse==1.6.3 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (1.6.3) Requirement already satisfied: opt-einsum&gt;=2.3.2 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (3.3.0) Requirement already satisfied: google-pasta&gt;=0.1.8 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (0.2.0) Requirement already satisfied: grpcio&gt;=1.8.6 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (1.31.0) Requirement already satisfied: typeguard&gt;=2.7 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow-addons&gt;=0.8.2-&gt;tf2crf-&gt;urduhack[tf]) (2.9.1) Requirement already satisfied: certifi&gt;=2017.4.17 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from requests&gt;=2.19.0-&gt;tensorflow-datasets~=3.1-&gt;urduhack[tf]) (2020.6.20) Requirement already satisfied: idna&lt;3,&gt;=2.5 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from requests&gt;=2.19.0-&gt;tensorflow-datasets~=3.1-&gt;urduhack[tf]) (2.10) Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,&lt;1.26,&gt;=1.21.1 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from requests&gt;=2.19.0-&gt;tensorflow-datasets~=3.1-&gt;urduhack[tf]) (1.25.10) Requirement already satisfied: chardet&lt;4,&gt;=3.0.2 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from requests&gt;=2.19.0-&gt;tensorflow-datasets~=3.1-&gt;urduhack[tf]) (3.0.4) Requirement already satisfied: googleapis-common-protos in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorflow-metadata-&gt;tensorflow-datasets~=3.1-&gt;urduhack[tf]) (1.52.0) Requirement already satisfied: setuptools in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from protobuf&gt;=3.6.1-&gt;tensorflow-datasets~=3.1-&gt;urduhack[tf]) (47.1.0) Requirement already satisfied: tensorboard-plugin-wit&gt;=1.6.0 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (1.7.0) Requirement already satisfied: google-auth&lt;2,&gt;=1.6.3 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (1.21.0) Requirement already satisfied: markdown&gt;=2.6.8 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (2.6.11) Requirement already satisfied: google-auth-oauthlib&lt;0.5,&gt;=0.4.1 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (0.4.1) Requirement already satisfied: werkzeug&gt;=0.11.15 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (0.16.1) Requirement already satisfied: pyasn1-modules&gt;=0.2.1 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (0.2.8) Requirement already satisfied: rsa&lt;5,&gt;=3.1.4; python_version &gt;= &#34;3.5&#34; in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (4.6) Requirement already satisfied: cachetools&lt;5.0,&gt;=2.0.0 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (4.1.1) Requirement already satisfied: requests-oauthlib&gt;=0.7.0 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (1.3.0) Requirement already satisfied: pyasn1&lt;0.5.0,&gt;=0.4.6 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from pyasn1-modules&gt;=0.2.1-&gt;google-auth&lt;2,&gt;=1.6.3-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (0.4.8) Requirement already satisfied: oauthlib&gt;=3.0.0 in /Users/ikramali/.pyenv/versions/3.7.8/envs/test/lib/python3.7/site-packages (from requests-oauthlib&gt;=0.7.0-&gt;google-auth-oauthlib&lt;0.5,&gt;=0.4.1-&gt;tensorboard&lt;3,&gt;=2.3.0-&gt;tensorflow~=2.2; extra == &#34;tf&#34;-&gt;urduhack[tf]) (3.1.0) Installing collected packages: urduhack Successfully installed urduhack-1.1.1 WARNING: You are using pip version 20.1.1; however, version 20.2.3 is available. You should consider upgrading via the &#39;/Users/ikramali/.pyenv/versions/3.7.8/envs/test/bin/python3.7 -m pip install --upgrade pip&#39; command. . from urduhack.urdu_characters import URDU_ALPHABETS,URDU_DIGITS,URDU_PUNCTUATIONS,URDU_DIACRITICS,URDU_ALL_CHARACTERS . print(URDU_ALPHABETS, end=&#39; &#39;) . frozenset({&#39;گ&#39;, &#39;ز&#39;, &#39;ٹ&#39;, &#39;ص&#39;, &#39;س&#39;, &#39;ت&#39;, &#39;ح&#39;, &#39;ک&#39;, &#39;خ&#39;, &#39;ڈ&#39;, &#39;ر&#39;, &#39;ف&#39;, &#39;ھ&#39;, &#39;ج&#39;, &#39;چ&#39;, &#39;ؤ&#39;, &#39;ئ&#39;, &#39;ے&#39;, &#39;ق&#39;, &#39;ب&#39;, &#39;ڑ&#39;, &#39;ط&#39;, &#39;ل&#39;, &#39;ث&#39;, &#39;ۓ&#39;, &#39;ذ&#39;, &#39;ژ&#39;, &#39;ء&#39;, &#39;پ&#39;, &#39;آ&#39;, &#39;ض&#39;, &#39;ی&#39;, &#39;ن&#39;, &#39;ۂ&#39;, &#39;أ&#39;, &#39;ش&#39;, &#39;غ&#39;, &#39;م&#39;, &#39;ا&#39;, &#39;د&#39;, &#39;ہ&#39;, &#39;ظ&#39;, &#39;ۃ&#39;, &#39;ں&#39;, &#39;ع&#39;, &#39;و&#39;}) . print(URDU_DIGITS, end=&#39; &#39;) . frozenset({&#39;۱&#39;, &#39;۵&#39;, &#39;۶&#39;, &#39;۰&#39;, &#39;۳&#39;, &#39;۴&#39;, &#39;۲&#39;, &#39;۸&#39;, &#39;۹&#39;, &#39;۷&#39;}) . print(URDU_PUNCTUATIONS, end=&#39; &#39;) . frozenset({&#39;؛&#39;, &#39;؟&#39;, &#39;٪&#39;, &#39;،&#39;, &#39;٫&#39;, &#39;۔&#39;}) . print(URDU_DIACRITICS, end=&#39; &#39;) . frozenset({&#39;ٍ&#39;, &#39;ِ&#39;, &#39;ً&#39;, &#39;ٰ&#39;, &#39;ُ&#39;, &#39;َ&#39;}) . print(URDU_ALL_CHARACTERS) . frozenset({&#39;گ&#39;, &#39;ز&#39;, &#39;ؔ&#39;, &#39;۱&#39;, &#39;ؑ&#39;, &#39;ح&#39;, &#39;۴&#39;, &#39;ؓ&#39;, &#39;ر&#39;, &#39;؛&#39;, &#39;ھ&#39;, &#39; u0601&#39;, &#39;ج&#39;, &#39;ب&#39;, &#39;؍&#39;, &#39;ل&#39;, &#39;ث&#39;, &#39;ۓ&#39;, &#39;ذ&#39;, &#39;ژ&#39;, &#39;ً&#39;, &#39;آ&#39;, &#39;ؕ&#39;, &#39;ض&#39;, &#39;ی&#39;, &#39;ن&#39;, &#39;۰&#39;, &#39;۸&#39;, &#39;غ&#39;, &#39;ا&#39;, &#39;ٔ&#39;, &#39;؏&#39;, &#39;۲&#39;, &#39; u0602&#39;, &#39;٬&#39;, &#39;ظ&#39;, &#39;ۃ&#39;, &#39;۹&#39;, &#39;۔&#39;, &#39;ُ&#39;, &#39;ٹ&#39;, &#39;ص&#39;, &#39;س&#39;, &#39;ٌ&#39;, &#39;٘&#39;, &#39;ت&#39;, &#39;ک&#39;, &#39;خ&#39;, &#39;ڈ&#39;, &#39;ْ&#39;, &#39;ف&#39;, &#39; u0600&#39;, &#39;ٗ&#39;, &#39;،&#39;, &#39;۵&#39;, &#39;چ&#39;, &#39;ؤ&#39;, &#39;ئ&#39;, &#39;ے&#39;, &#39;ق&#39;, &#39;٫&#39;, &#39;ٖ&#39;, &#39;ط&#39;, &#39;ڑ&#39;, &#39;۷&#39;, &#39;ٍ&#39;, &#39;ِ&#39;, &#39;ء&#39;, &#39;پ&#39;, &#39;۶&#39;, &#39;ّ&#39;, &#39;ؐ&#39;, &#39;۳&#39;, &#39;ۂ&#39;, &#39;ؒ&#39;, &#39;أ&#39;, &#39;ش&#39;, &#39;ٰ&#39;, &#39;م&#39;, &#39;د&#39;, &#39;ٓ&#39;, &#39;؟&#39;, &#39;٪&#39;, &#39; u0603&#39;, &#39;ہ&#39;, &#39;؎&#39;, &#39;ں&#39;, &#39;ع&#39;, &#39;َ&#39;, &#39;و&#39;}) . Urdu vs Arabic Presentation form Characters Challenge . Unicode provides support for Urdu language but there is a problem we have to cater in order to utilise that support. The Urdu is incorporated in Arabic language&#39;s block in the Unicode table as Urdu is derived from Arabic script. This makes things a little bit complicated for computer scientists trying to develop applications for Urdu language. . For example consider a word &quot;خاموشی&quot;, now if we see the codes at the back-end for this word we can find two different sets of codes form Unicode table. . . . Now the problem is how do we know on which codes we have to train our model on? If we train our model on a specific range (Urdu 0600-06ff) and our dataset has some words formed using the Arabic set of codes then our application will fail to recognize those words resulting in low accuracy. This redundancy in codes of words hinders us to achieve a high accuracy. . So how do we handle this issue? You can go up and look at the Urdu Unicode Range table. Unicode has standardized this range (0600-06ff) for Urdu only. So all we need to do is to do some data pre-processing before running any alogrithm on data. For each word in data having redundant codes, we can replace that word with the same standardized Urdu word belonging to the range 0600 to 06ff. That&#39;s it! . Urdu Characters Shapes . Urdu characters take on different forms based on the position they are used inside a word. Like an urdu character used at the start of a word will have a different shape and the same character used in the middle or at the end of a word will have a completely different shape. This is only concerned with the font shape for that character. For illustration purpose, let&#39;s take an example of urdu character &quot;ﻑ&quot;. Now notice the difference in &quot;ﻑ&quot; shape. . Used at the Start: &quot;آفاق&quot; | Used in the middle: &quot;مفاحمت&quot; | Used at the End: &quot;کیف&quot; | Isolated Use: &quot;موصوف&quot; | . As you would have noticed &quot;ﻑ&quot; takes on a different shape based on its position of usage. . . Urdu/Arabic Character Presentation Fonts . Now to get a bit more understanding of the above part, let&#39;s look at the unicode range for combined characters. These combined characters are given a unicode range separately. This range was defined for the intuition purpose only. How two characters appear when they are combined. It has more to do with the usage of characters in different positions rather than the context the character is used in. In arabic &quot;Qaida&quot;, for teaching purpose, it is taught how two characters like &quot;ل&quot; and &quot;ح&quot; when combined will appear like &quot;لح&quot;. This &quot;لح&quot; is given a new unicode FC40. There wil hardly be any keyboard or a system which will use these combined characters so this just to show different presentation forms of a character. For more illustrative purpose, look at the below links. . Unicode Charts | Arabic Presentations Forms-A | Arabic Presentation Forms-B | . Comparison of Unicode values of Urdu and Arabic characters . Thanks to (https://github.com/urdutext/UrduArabicCompare) CSV file (https://github.com/urduhack/urdu-characters/blob/master/img/Urdu_Arabic_Unicode_comparison.csv) . .",
            "url": "https://urduhack.com/2020/10/16/urdu-unicode-ranges-explained.html",
            "relUrl": "/2020/10/16/urdu-unicode-ranges-explained.html",
            "date": " • Oct 16, 2020"
        }
        
    
  
    
        ,"post1": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master- badges: true- comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://urduhack.com/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  
    
        ,"post2": {
            "title": "UrduHack NLP library.",
            "content": "UrduHack NLP library . Urdu is widely known as the national language of Pakistan but unfortunately, it is getting obsolete with each passing day in this modern world. Our vision is to make Urdu stand on its feet and work as good as English with modern tech. We have developed the very first Python library for Urdu called UrduHack. It is completely free to use aka OPEN SOURCE! . We have developed two core modules, Normalization and Tokenization, which are necessary to build ML models for complex problems like Sentiment Analysis or Document Classification etc. It’s under development currently and we are working daily to make this a full-fledged NLP library for Urdu. You can easily get the idea about the tasks we are working on by visiting the given links. . Machine Learning models supported by urduhack: . Text Classification | Sentimental Analysis | Sentence Classification | Documents Classification | Named Entity Recognition | Image to Text | Speech to Text | . UrduHack is completely open-source and we want to keep it that way aka a non-profit library. The biggest problem we have faced till now is having a solid Urdu dataset. We have written many algorithms to form a good dataset but we are still far behind from producing a 100% correct one. . Urduhack as a Package: . Available on github: urduhack . Available on Pypi: urduhack . Urduhack Documentation: urduhack docs .",
            "url": "https://urduhack.com/nlp/python/2020/01/14/UrduHack-nlp-library.html",
            "relUrl": "/nlp/python/2020/01/14/UrduHack-nlp-library.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://urduhack.com/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://urduhack.com/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}